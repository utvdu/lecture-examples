{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Image Compression using Autoencoders with BPSK\n",
    "\n",
    "This code is provided as supplementary material of the lecture Machine Learning and Optimization in Communications (MLOC).<br>\n",
    "\n",
    "This code illustrates\n",
    "* joint compression and error protection of images by auto-encoders\n",
    "* generation of BPSK symbols using stochastic quantizers\n",
    "* transmission over a binary symmetric channel (BSC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We are using the following device for learning: cuda\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(\"We are using the following device for learning:\",device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import and load MNIST dataset (Preprocessing)\n",
    "Dataloader are powerful instruments, which help you to prepare your data. E.g. you can shuffle your data, transform data (standardize/normalize), divide it into batches, ...  For more information see https://pytorch.org/docs/stable/data.html#torch.utils.data.DataLoader <br>\n",
    "\n",
    "In our case, we just use the dataloader to download the Dataset and preprocess the data on our own."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size_train = 60000      # Samples per Training Batch\n",
    "batch_size_test = 10000     # just create one large test dataset (MNIST test dataset has 10.000 Samples)\n",
    "\n",
    "# Get Training and Test Dataset with a Dataloader\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "  torchvision.datasets.MNIST('./files/', train=True, download=True,\n",
    "  transform=torchvision.transforms.Compose([torchvision.transforms.ToTensor()])),\n",
    "  batch_size=batch_size_train, shuffle=True)\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "  torchvision.datasets.MNIST('./files/', train=False, download=True,\n",
    "  transform=torchvision.transforms.Compose([torchvision.transforms.ToTensor()])),\n",
    "  batch_size=batch_size_test, shuffle=True)\n",
    "\n",
    "# We are only interessted in the data and not in the targets\n",
    "for idx, (data, targets) in enumerate(train_loader):\n",
    "    x_train = data[:,0,:,:]\n",
    "\n",
    "for idx, (data, targets) in enumerate(test_loader):\n",
    "    x_test = data[:,0,:,:]\n",
    "\n",
    "image_size = x_train.shape[1]\n",
    "x_test_flat = torch.reshape(x_test, (x_test.shape[0], image_size*image_size))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot 8 random images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1152x144 with 8 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(16,2))\n",
    "for k in range(8):\n",
    "    plt.subplot(1,8,k+1)\n",
    "    plt.imshow(x_train[np.random.randint(x_train.shape[0])], interpolation='nearest', cmap='binary')\n",
    "    plt.xticks(())\n",
    "    plt.yticks(())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Specify Autoencoder\n",
    "As explained in the lecture, we are using Stochstic Quantization. This means for the training process (*def forward*), we employ stochastic quantization in forward path but during back-propagation, we consider the quantization device as being\n",
    "non-existent (*.detach()*). While validating and testing, use deterministic quantization (*def test*) <br>\n",
    "\n",
    "\n",
    "*Note: .detach() removes the tensor from the computation graph*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden_encoder_1 = 500\n",
    "hidden_encoder_2 = 250\n",
    "hidden_encoder_3 = 100\n",
    "hidden_encoder = [hidden_encoder_1, hidden_encoder_2, hidden_encoder_3]\n",
    "\n",
    "hidden_decoder_1 = 100\n",
    "hidden_decoder_2 = 250\n",
    "hidden_decoder_3 = 500\n",
    "hidden_decoder = [hidden_decoder_1, hidden_decoder_2, hidden_decoder_3]\n",
    "\n",
    "\n",
    "class Autoencoder(nn.Module):\n",
    "    def __init__(self, hidden_encoder, hidden_decoder, image_size, bit_per_image):\n",
    "        super(Autoencoder, self).__init__()\n",
    "       \n",
    "        # Define Transmitter Layer: Linear function, M input neurons (symbols), 2 output neurons (real and imaginary part)        \n",
    "        self.We1 = nn.Linear(image_size*image_size, hidden_encoder[0]) \n",
    "        self.We2 = nn.Linear(hidden_encoder[0], hidden_encoder[1]) \n",
    "        self.We3 = nn.Linear(hidden_encoder[1], hidden_encoder[2]) \n",
    "        self.We4 = nn.Linear(hidden_encoder[2], bit_per_image)         \n",
    "        \n",
    "        # Define Receiver Layer: Linear function, 2 input neurons (real and imaginary part), M output neurons (symbols)\n",
    "        self.Wd1 = nn.Linear(bit_per_image,hidden_decoder[0]) \n",
    "        self.Wd2 = nn.Linear(hidden_decoder[0], hidden_decoder[1]) \n",
    "        self.Wd3 = nn.Linear(hidden_decoder[1], hidden_decoder[2]) \n",
    "        self.Wd4 = nn.Linear(hidden_decoder[2], image_size*image_size) \n",
    "\n",
    "        # Non-linearity (used in transmitter and receiver)\n",
    "        self.activation_function = nn.ELU()    \n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        self.softsign = nn.Softsign()\n",
    "\n",
    "    def forward(self, training_data, Pe):\n",
    "        encoded = self.encoder(training_data)\n",
    "        # random binarization in training\n",
    "        ti = encoded.clone()\n",
    "        compressed = ti + (self.binarizer(ti) - ti).detach()\n",
    "        # add error pattern (flip the bit or not)\n",
    "        error_tensor = torch.distributions.Bernoulli(Pe * torch.ones_like(compressed)).sample() \n",
    "        received = torch.mul( compressed, 1 - 2*error_tensor)\n",
    "        \n",
    "        reconstructed = self.decoder(received)\n",
    "        return reconstructed\n",
    "        \n",
    "    def test(self, valid_data, Pe):\n",
    "        encoded_test = self.encoder(valid_data)\n",
    "        compressed_test = self.binarizer_deterministic(encoded_test)\n",
    "        error_tensor_test = torch.distributions.Bernoulli(Pe * torch.ones_like(compressed_test)).sample()\n",
    "        received_test = torch.mul( compressed_test, 1 - 2*error_tensor_test )\n",
    "        reconstructed_test = self.decoder(received_test)\n",
    "        loss_test = torch.mean(torch.square(valid_data - reconstructed_test))\n",
    "\n",
    "        reconstructed_test_noerror = self.decoder(compressed_test)\n",
    "        return reconstructed_test\n",
    "        \n",
    "    def encoder(self, batch):\n",
    "        temp = self.activation_function(self.We1(batch))\n",
    "        temp = self.activation_function(self.We2(temp))\n",
    "        temp = self.activation_function(self.We3(temp))\n",
    "        output = self.softsign(self.We4(temp))\n",
    "        return output\n",
    "    \n",
    "    def decoder(self, batch):\n",
    "        temp = self.activation_function(self.Wd1(batch))\n",
    "        temp = self.activation_function(self.Wd2(temp))\n",
    "        temp = self.activation_function(self.Wd3(temp))\n",
    "        output = self.sigmoid(self.Wd4(temp))\n",
    "        return output\n",
    "    \n",
    "    def binarizer(self, input):\n",
    "        # This is the stochastic quatizer which we use for the training\n",
    "        prob = torch.div(torch.add(input, 1.0), 2.0)\n",
    "        bernoulli = torch.distributions.Bernoulli(prob)  # torch.distributions.bernoulli.\n",
    "        # bernoulli = tf.distributions.Bernoulli(probs=prob, dtype=tf.float32)\n",
    "        return 2*bernoulli.sample() - 1\n",
    "\n",
    "    def binarizer_deterministic(self, input):\n",
    "        # This is the deteministic quatizer which we use for \n",
    "        return torch.sign(input)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Helper function to get a random mini-batch of images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_batch(x, batch_size):\n",
    "    idxs = np.random.randint(0, x.shape[0], (batch_size))\n",
    "    return torch.stack([torch.reshape(x[k], (-1,)) for k in idxs])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Perform the training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing ....\n",
      "Start Training\n",
      "Pe = 0.00, bits = 5, It 0: (best SNR: -2.8957 dB)\n",
      "Pe = 0.00, bits = 5, It 10000: (best SNR: 4.0096 dB)\n",
      "Pe = 0.00, bits = 5, It 20000: (best SNR: 4.0227 dB)\n",
      "Pe = 0.00, bits = 5, It 30000: (best SNR: 4.0227 dB)\n",
      "Pe = 0.00, bits = 5, It 40000: (best SNR: 4.0241 dB)\n",
      "Pe = 0.00, bits = 5, It 50000: (best SNR: 4.0243 dB)\n",
      "Pe = 0.00, bits = 5, It 60000: (best SNR: 4.0243 dB)\n",
      "Pe = 0.00, bits = 5, It 70000: (best SNR: 4.0255 dB)\n",
      "Pe = 0.00, bits = 5, It 80000: (best SNR: 4.0304 dB)\n",
      "Pe = 0.00, bits = 5, It 90000: (best SNR: 4.0304 dB)\n",
      "Finished learning for e = 0.00, bits = 5. Best SNR: 4.0304\n",
      "Initializing ....\n",
      "Start Training\n",
      "Pe = 0.00, bits = 10, It 0: (best SNR: -2.9289 dB)\n",
      "Pe = 0.00, bits = 10, It 10000: (best SNR: 5.1916 dB)\n",
      "Pe = 0.00, bits = 10, It 20000: (best SNR: 5.3070 dB)\n",
      "Pe = 0.00, bits = 10, It 30000: (best SNR: 5.3852 dB)\n",
      "Pe = 0.00, bits = 10, It 40000: (best SNR: 5.4082 dB)\n",
      "Pe = 0.00, bits = 10, It 50000: (best SNR: 5.4334 dB)\n",
      "Pe = 0.00, bits = 10, It 60000: (best SNR: 5.4424 dB)\n",
      "Pe = 0.00, bits = 10, It 70000: (best SNR: 5.4569 dB)\n",
      "Pe = 0.00, bits = 10, It 80000: (best SNR: 5.4639 dB)\n"
     ]
    }
   ],
   "source": [
    "batch_size = 250\n",
    "Pe_range = np.array([0, 0.01, 0.1, 0.2])\n",
    "bit_range = np.array([5, 10, 20, 30, 40, 50, 60, 70, 80, 100])\n",
    "\n",
    "SNR_result = np.zeros( (len(Pe_range), len(bit_range)) )\n",
    "\n",
    "# Mean Squared Error loss\n",
    "loss_fn = nn.MSELoss()\n",
    "\n",
    "\n",
    "\n",
    "for i in range(len(Pe_range)):\n",
    "    for j in range(len(bit_range)):\n",
    "        best_SNR = -9999;\n",
    "        print('Initializing ....')\n",
    "        \n",
    "        model = Autoencoder(hidden_encoder, hidden_decoder, image_size, bit_range[j])\n",
    "        model.to(device)\n",
    "\n",
    "\n",
    "        # Adam Optimizer\n",
    "        optimizer = optim.Adam(model.parameters())    \n",
    "    \n",
    "        print('Start Training')   # Training loop\n",
    "\n",
    "        for it in range(100000):  # Original paper does 50k iterations  \n",
    "            mini_batch = torch.Tensor(get_batch(x_train, batch_size)).to(device)\n",
    "            # Propagate (training) data through the net\n",
    "            reconstructed = model(mini_batch, Pe_range[i])\n",
    "    \n",
    "            # compute loss\n",
    "            loss = loss_fn(mini_batch, reconstructed)\n",
    "\n",
    "            # compute gradients\n",
    "            loss.backward()\n",
    "\n",
    "            # Adapt weights\n",
    "            optimizer.step()\n",
    "\n",
    "            # reset gradients\n",
    "            optimizer.zero_grad()\n",
    "    \n",
    "            # Evaulation with the test data\n",
    "            if it % 500 == 0:\n",
    "                reconstructed_test = model.test(x_test_flat.to(device), Pe_range[i])\n",
    "                noise =  torch.mean(torch.square(x_test_flat.to(device) - reconstructed_test))\n",
    "                SNR = 10.0 * (torch.log(torch.mean(torch.square(x_test_flat.to(device)))) - torch.log(noise)) / np.log(10.0)                \n",
    "                cur_SNR = SNR.detach().cpu().numpy().squeeze()\n",
    "                if cur_SNR > best_SNR:\n",
    "                    best_SNR = cur_SNR\n",
    "                    \n",
    "            if it % 10000 == 0:            \n",
    "                print('Pe = %1.2f, bits = %d, It %d: (best SNR: %1.4f dB)' % (Pe_range[i], bit_range[j], it, best_SNR))\n",
    "        \n",
    "        SNR_result[i,j] = best_SNR\n",
    "        print('Finished learning for e = %1.2f, bits = %d. Best SNR: %1.4f' % (Pe_range[i], bit_range[j], best_SNR))\n",
    "    \n",
    "print('Training finished')\n",
    "np.savetxt('SNR_result.txt', SNR_result, delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
